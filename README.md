# Multi-view-Multi-label-learning
This repository is dedicated to our research on multi-view multi-label learning, an emerging field that focuses on learning from multiple views or modalities, each providing different information about the same set of labels. Our work explores advanced algorithms and models to enhance feature selection, classification accuracy, and understanding in multi-modal data environments.
(keywords:multi-view, multi-label, supervised learning, sparse models, python, datasets)

## Publications

Our research includes the following articles that detail our methodologies and findings:

1. **"Uncertainty-Aware Global-View Reconstruction for Multi-View Multi-Label Feature Selection"**-[Proceedings of the AAAI Conference on Artificial Intelligence. 2025]()
2. **"Embedded feature fusion for multi-view multi-label feature selection"** - [Pattern Recognition, 157 (2025) 110888](https://www.sciencedirect.com/science/article/pii/S0031320324006393)
3. **"Double-Layer Hybrid-Label Identification Feature Selection for Multi-View Multi-Label Learning"**-[Proceedings of the AAAI Conference on Artificial Intelligence. 2024, 38(11): 12295-12303](https://ojs.aaai.org/index.php/AAAI/article/view/29120)
4. **"Anchor-guided global view reconstruction for multi-view multi-label feature selection"** - [Information Sciences, 679 (2024) 121124](https://www.sciencedirect.com/science/article/pii/S0020025524010387)
5. **"Anchor-guided global view reconstruction for multi-view multi-label feature selection"** - [Information Sciences, 681 (2024) 121215](https://www.sciencedirect.com/science/article/pii/S0020025524011290)


## Datasets

The following datasets have been utilized in our research and are referenced within the aforementioned articles:

- **yeast**
- **VOC07**
- **SCENE**
- **OBJECT**
- **MIRFlickr**
- **iaprtc12**
- **espgame**
- **emotions**
- **corel5k**
- **3sources**

Original addresses for these datasets can be found within the linked articles above.

## Citation

We kindly invite researchers and academics to cite our work in their research. Your citations help contribute to the advancement of multi-view multi-label learning research and are greatly appreciated.

## Contribution

We welcome contributions from the community, including bug reports, new features, and improvements. Please feel free to open an issue or submit a pull request.

## Contact

For any inquiries or collaboration opportunities, please contact:

- Postdoc. [Pingting Hao] ([862316425@qq.com(wxÂêå)](mailto:haopingting@jlu.edu.cn))
- [Jilin University]

Thank you for your interest in our research!



